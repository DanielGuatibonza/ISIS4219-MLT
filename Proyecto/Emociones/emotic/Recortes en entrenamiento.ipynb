{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-equilibrium",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_local = VGG16(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(*SIZE, 3)))\n",
    "vgg_local.trainable = False\n",
    "\n",
    "flatten_bbox_local = Flatten()(vgg_local.output)\n",
    "dense_1_bbox_local = Dense(128, activation = 'relu')(flatten_bbox_local)\n",
    "dense_2_bbox_local = Dense(32, activation = 'relu')(dense_1_bbox_local)\n",
    "output_bbox_local = Dense(4, activation = lambda x: 200*tf.keras.activations.sigmoid(x))(dense_2_bbox_local)\n",
    "model_bbox_base_local = Model(inputs = vgg_local.inputs, outputs = output_bbox_local)\n",
    "\n",
    "model_bbox_base_local.compile(optimizer = keras.optimizers.Adam(learning_rate=0.0001), loss = 'mse')\n",
    "model_bbox_base_local.load_weights('modelo_bbox_mse_weights')\n",
    "\n",
    "@tf.function\n",
    "def parse_ds_reg_cut_function(example_input: Optional[tf.Tensor],) -> Optional[Tuple[tf.Tensor]]:\n",
    "    image = tf.io.read_file(example_input[0])\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, SIZE)\n",
    "    image = tf.cast(image, tf.float32) / 255.\n",
    "\n",
    "    bbox_predict = model_bbox_base_local(tf.expand_dims(image, axis=0))\n",
    "    image = tf.image.crop_and_resize(tf.expand_dims(image, axis=0), \n",
    "                                     tf.math.divide(bbox_predict, tf.constant(200.)), \n",
    "                                     tf.random.uniform(shape=(1,), minval=0, maxval=1, dtype=tf.int32), \n",
    "                                     SIZE)\n",
    "\n",
    "    val = tf.strings.to_number(example_input[1])\n",
    "    exc = tf.strings.to_number(example_input[2])\n",
    "    dom = tf.strings.to_number(example_input[3])\n",
    "\n",
    "    return tf.squeeze(image), [val, exc, dom]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geographic-multiple",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_reg_cut = train_list_ds_reg.map(parse_ds_reg_cut_function)\n",
    "val_ds_reg_cut = val_list_ds_reg.map(parse_ds_reg_cut_function)\n",
    "test_ds_reg_cut = test_list_ds_reg.map(parse_ds_reg_cut_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-democrat",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_reg_cut  = performance(train_ds_reg_cut)\n",
    "val_ds_reg_cut = performance(val_ds_reg_cut, False)\n",
    "test_ds_reg_cut = performance(test_ds_reg_cut, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-employer",
   "metadata": {},
   "outputs": [],
   "source": [
    "for X_batch, y_batch in val_ds_reg_cut.take(1):\n",
    "    break\n",
    "np.random.seed(0)\n",
    "random_sample = np.random.choice(len(X_batch), 9)\n",
    "X_img = X_batch.numpy()[random_sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-casting",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_subplot([img for img in X_img], [\"\" for _ in X_img], (3, 3), (10, 10),)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
